{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56562ddf",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Notebook\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will explore the Ames housing data which contains information about the sale of individual residential properties in Ames, Iowa.\n",
    "\n",
    "The major steps involved in this exploratory data analysis are as follows:\n",
    "\n",
    "- Load and inspect the data\n",
    "- Identify missing values\n",
    "- Explore distributions of key variables\n",
    "- Find correlations between variables\n",
    "- Generate visualizations for insights into the data\n",
    "\n",
    "This process will allow us to better understand the data and determine what preprocessing and feature engineering need to be done before modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a7fd6",
   "metadata": {},
   "source": [
    "## Importing Libraries and Setting Style\n",
    "\n",
    "First, we import the necessary libraries for our analysis: `pandas` for data manipulation, `numpy` for numerical operations, `matplotlib` for basic plotting, and `seaborn` for more advanced visualization.\n",
    "\n",
    "We also set the color palette to a pastel one and the style to `whitegrid` using `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ff912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153521d",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "We start by reading in the training and test datasets using `pandas`'s `read_csv()` function. The `train_df` and `test_df` dataframes are created to store the data from the corresponding CSV files.\n",
    "\n",
    "We then print the shapes of the two dataframes to check the number of rows and columns in each. The `train_df` dataframe contains X rows and Y columns, while the `test_df` dataframe contains A rows and B columns.\n",
    "\n",
    "Finally, we print the number of rows in the training and test datasets using `len()`. The training dataset contains training rows, while the test dataset contains test rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5052d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data_details/train.csv')\n",
    "test_df = pd.read_csv('../data_details/test.csv')\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "\n",
    "print(f\"Training rows: {len(train_df)}\") \n",
    "print(f\"Test rows: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d189a00",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "To get a better understanding of our data, we inspect the first few rows, last few rows, and a random sample of the `train_df` dataframe using the `head()`, `tail()`, and `sample()` functions, respectively. These functions allow us to quickly view the data and check for any obvious issues or anomalies.\n",
    "\n",
    "The `head()` function displays the first few rows of the dataframe, while the `tail()` function displays the last few rows. The `sample()` function displays a random sample of rows from the dataframe.\n",
    "\n",
    "By inspecting the data, we can get a sense of the variables and their values, as well as any missing data or other issues that may need to be addressed during preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inspection\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.dtypes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482073d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = train_df.isnull().sum()\n",
    "print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecb66b",
   "metadata": {},
   "source": [
    "## Exploring Distribution of Target\n",
    "\n",
    "\n",
    "We plot a histogram of the target variable - variable we want to predict - SalePrice to understand its distribution. This helps us determine appropriate models and transformations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(train_df['SalePrice'], bins=30, color='pink', edgecolor='black')\n",
    "plt.title('Distribution of Sale Prices')\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86aef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation of numerical variables\n",
    "correlation = train_df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "# sort the correlations of the features with SalePrice\n",
    "print(\"Correlation with SalePrice:\")\n",
    "correlation['SalePrice'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the top 10 most positively correlated features with SalePrice\n",
    "top_corr_features = correlation['SalePrice'].sort_values(ascending=False).head(11).index\n",
    "\n",
    "# Creating a correlation matrix for the top correlated features\n",
    "corr_matrix = train_df[top_corr_features].corr()\n",
    "\n",
    "# Setting up the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting the heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdPu')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd69296",
   "metadata": {},
   "source": [
    "We can observe strong positive correlations between SalePrice and features like OverallQual, GrLivArea, GarageCars, GarageArea, and TotalBsmtSF, as we discussed earlier.\n",
    "\n",
    "We can also see some correlation between the predictors themselves. For example, GarageCars and GarageArea are highly correlated (0.88), which makes sense - the more cars that fit into a garage, the larger the garage area tends to be. Similarly, GrLivArea and TotRmsAbvGrd have a high correlation (0.83) because houses with more rooms are likely to have a larger living area.\n",
    "\n",
    "We'll need to consider this multicollinearity, as highly correlated predictors can sometimes negatively impact certain types of regression models. For example, in linear regression, high levels of multicollinearity can cause the coefficients of the predictors to be unstable and difficult to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d18188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variables to explore\n",
    "vars_to_explore = ['GrLivArea', 'OverallQual', 'Neighborhood', 'YearBuilt', 'LotArea', 'YearRemodAdd', 'BsmtQual']\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(nrows=len(vars_to_explore), figsize=(12, 6*len(vars_to_explore)))\n",
    "\n",
    "for i, var in enumerate(vars_to_explore):\n",
    "    # Scatter plot for numerical variables\n",
    "    if train_df[var].dtype in ['int64', 'float64']:\n",
    "        axs[i].scatter(train_df[var], train_df['SalePrice'])\n",
    "        axs[i].set_title(f'SalePrice vs {var}')\n",
    "        axs[i].set_xlabel(var)\n",
    "        axs[i].set_ylabel('SalePrice')\n",
    "    # Box plot for categorical variables\n",
    "    else:\n",
    "        sns.boxplot(x=var, y='SalePrice', data=train_df, ax=axs[i])\n",
    "        axs[i].set_title(f'SalePrice by {var}')\n",
    "        axs[i].set_xlabel(var)\n",
    "        axs[i].set_ylabel('SalePrice')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd02c0",
   "metadata": {},
   "source": [
    "GrLivArea: As expected, there seems to be a positive correlation between 'GrLivArea' and 'SalePrice'. Larger living areas generally lead to higher sale prices. However, there are a few exceptions (outliers) where large houses sold for relatively low prices. This might indicate that other factors (e.g., the quality of the house, the neighborhood, etc.) can significantly influence the sale price.\n",
    "\n",
    "OverallQual: The box plots clearly show that the 'SalePrice' increases with 'OverallQual'. The interquartile range (IQR, the range within which the middle 50% of the prices fall) also increases with 'OverallQual'. This suggests that higher quality houses not only sell for higher prices on average, but the price variability is also higher for these houses.\n",
    "\n",
    "Neighborhood: The sale price appears to vary significantly by neighborhood. Some neighborhoods like 'NoRidge', 'NridgHt', and 'StoneBr' have much higher median prices compared to others. This confirms that location is a crucial factor in determining house prices.\n",
    "\n",
    "YearBuilt: There seems to be a slight upward trend in prices for more recently built houses, which is expected as newer houses tend to have modern designs and require less maintenance. However, the trend is not very strong, indicating that other factors also play a significant role in determining prices.\n",
    "\n",
    "LotArea: While there's a general trend of larger lots commanding higher prices, the relationship is not very strong. There are many small lots that sold for high prices, and some large lots that sold for relatively low prices. This might indicate that the utility of a larger lot diminishes after a certain point.\n",
    "\n",
    "YearRemodAdd: Houses that were remodeled more recently tend to sell for higher prices. This is consistent with the expectation that buyers would pay more for more modern and updated features.\n",
    "\n",
    "BsmtQual: The sale price seems to increase with the quality of the basement, with 'Ex' (Excellent) basements commanding the highest prices. The variation in price also seems to increase with basement quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d37ae0",
   "metadata": {},
   "source": [
    "##  Numeric feature distributions\n",
    "\n",
    "We look at the distribution, shape, and outliers of the key numeric columns/features. This informs data scaling/normalization and transformation needs later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc02fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for GrLivArea\n",
    "plt.hist(train_df['GrLivArea'], bins=30, color='pink', edgecolor='black')\n",
    "plt.title('Distribution of GrLivArea')\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for LotArea\n",
    "plt.hist(train_df['LotArea'], bins=20, color='pink', edgecolor='black')\n",
    "plt.title('Distribution of LotArea')\n",
    "plt.xlabel('LotArea')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(train_df[['GrLivArea', 'LotArea', '1stFlrSF']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193796b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "plt.hist(train_df['GrLivArea'])\n",
    "plt.hist(train_df['LotArea'])\n",
    "\n",
    "# Boxplots\n",
    "plt.boxplot(train_df['GrLivArea'])\n",
    "plt.boxplot(train_df['LotArea'])\n",
    "\n",
    "# Summary stats\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d8276",
   "metadata": {},
   "source": [
    "## Discrete feature analysis\n",
    "\n",
    "We're looking at features that fall into specific buckets or groups, like number of bedrooms and bathrooms. This is like sorting marbles by color and counting how many of each color there are.\n",
    "\n",
    "Seeing how many houses have 1 bedroom vs 2 vs 3 etc gives us insights into patterns in the data. We can do this grouping and counting for other categorical features too, like neighborhood or house style.\n",
    "\n",
    "I thought by creating count plots for the 'Bedrooms' and 'FullBath' features, we can begin to understand the distribution of these discrete features in our dataset. This can provide insights on common trends in the data such as the most common number of bedrooms or bathrooms in a house.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrooms\n",
    "plt.hist(train_df['BedroomAbvGr'], bins=9, color='pink', edgecolor='black')\n",
    "plt.xlabel('Bedrooms')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452d1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full bathrooms\n",
    "plt.hist(train_df['FullBath'], color='pink', edgecolor='black')  \n",
    "plt.xlabel('FullBath')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2f68",
   "metadata": {},
   "source": [
    "\n",
    "### Understanding Zoning\n",
    "\n",
    "Zoning refers to the local or municipal laws or regulations that dictate how real estate can and cannot be utilized within specific geographic regions. For instance, zoning laws might restrict commercial or industrial land use, ensuring that businesses related to oil, manufacturing, or other industries don't set up their premises in residential neighborhoods.\n",
    "\n",
    "The 'MSZoning' feature in our dataset signifies the general zoning classification of each property:\n",
    "\n",
    "- **RL - Residential Low Density**: This category includes properties where the housing density is low, with one unit or a small number of units per building.\n",
    "- **RM - Residential Medium Density**: This category includes properties with a higher number of units per building compared to low-density residential areas.\n",
    "- **FV - Floating Village Residential**: This category includes houses that are part of a village grouping with shared open spaces.\n",
    "- **RH - Residential High Density**: This category includes properties where the housing density is maximized, with the most possible number of units in each building.\n",
    "- **C (all) - Commercial**: This category includes areas that are intended for commercial business use.\n",
    "\n",
    "By evaluating the frequency of each unique zoning category in our dataset, we can gain an understanding of the property types and their distributions in our dataset.\n",
    "The MSZoning feature indicates the general zoning classification of each property such as residential low density (RL) or commercial (C).\n",
    "\n",
    "\n",
    "We will use The 'value_counts()' function to assess the frequency of each unique category within the 'MSZoning' categorical feature. This can help identify the most common zoning classification for houses in our dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value counts printed show the distribution of houses across these zoning types\n",
    "\n",
    "print('Frequency of values for MSZoning:')\n",
    "print(train_df['MSZoning'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ed526",
   "metadata": {},
   "source": [
    "We can see that the majority of houses (1151) are in residential low density areas (RL). There are also a good number (218) in residential medium density (RM) and some in floating village zones (FV). Only a small fraction are in high density (RH) or commercial (C) areas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neighborhood feature specifies which neighborhood each house belongs to. The value counts show the number of houses in each:\n",
    "\n",
    "print('\\nFrequency of values for Neighborhood:') \n",
    "print(train_df['Neighborhood'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca073f47",
   "metadata": {},
   "source": [
    "NAmes is the largest with 225 houses, while neighborhoods like Veenker only have 11 houses with Blueste having only 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569be15",
   "metadata": {},
   "source": [
    "## Location Analysis\n",
    "\n",
    "Exploring the relationships between location features and sale price allows us to explore insights like neighborhood price patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942efcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location analysis\n",
    "\n",
    "# Setting up the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Creating a boxplot of Neighborhood and SalePrice\n",
    "\n",
    "custom_color = (255/255, 51/255, 153/255) # RGB values for a bright pink color\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=train_df, color=custom_color)\n",
    "\n",
    "# sns.boxplot(x='Neighborhood', y='SalePrice', data=train_df, color='pink')\n",
    "\n",
    "# Rotating the x labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('SalePrice distribution by Neighborhood')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acad64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
